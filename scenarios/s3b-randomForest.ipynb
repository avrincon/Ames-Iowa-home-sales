{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ffeb69",
   "metadata": {},
   "source": [
    "# Scenario 3 B\n",
    "\n",
    "* Use random forest classifier to predict LogSalePrice. \n",
    "* Use features selected by Lasso and SequentialFeatureSelector\n",
    "* Implement ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\n",
    "    \"../data/ames_housing_clean_1.csv\",\n",
    "    keep_default_na=False,  \n",
    "    na_values=[\"\", \" \"],\n",
    "    dtype={'MSSubClass': 'str'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features to use\n",
    "selected_features = {\n",
    "    'BldgType', 'BsmtExposure', 'BsmtFinSF1', 'BsmtQual', 'Condition2', \n",
    "    'ExterCond', 'ExterQual', 'Exterior1st', 'Functional', 'GarageArea', \n",
    "    'GarageCond', 'GrLivArea', 'KitchenQual', 'MSSubClass', 'MSZoning', \n",
    "    'MasVnrArea', 'Neighborhood', 'OverallCond', 'OverallQual', 'RoofMatl', \n",
    "    'SaleCondition', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd'\n",
    "}\n",
    "\n",
    "df['LogSalePrice'] = np.log(df['SalePrice'])\n",
    "\n",
    "# Create feature matrix and target variable\n",
    "X = df[list(selected_features)]\n",
    "y = df['LogSalePrice']\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"\\nMissing values in features:\")\n",
    "missing_vals = X.isnull().sum()\n",
    "print(missing_vals[missing_vals > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify the categories for ordinal encoding according to the data dictionary\n",
    "ordinal_order = {\n",
    "    'ExterQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Evaluates the quality of the material on the exterior\n",
    "    'ExterCond': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Evaluates the present condition of the material on the exterior\n",
    "    'BsmtQual': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Height of the basement\n",
    "    'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],  # Walkout or garden level basement walls\n",
    "    'KitchenQual': ['Po', 'Fa', 'TA', 'Gd', 'Ex'],  # Kitchen quality\n",
    "    'Functional': ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],  # Home functionality\n",
    "    'GarageCond': ['None', 'Po', 'Fa', 'TA', 'Gd', 'Ex']  # Garage condition\n",
    "}\n",
    " \n",
    "# Extract list of ALL ordinal features from dictionary\n",
    "ordinal_features = list(ordinal_order.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6be107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric and categorical and nominal columns\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "nominal_features = [feature for feature in categorical_features if feature not in ordinal_features]\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "# print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "print(f\"Nominal features ({len(nominal_features)}): {nominal_features}\")\n",
    "print(f\"Ordinal features ({len(ordinal_features)}): {ordinal_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('ordinal', OrdinalEncoder(categories=[ordinal_order[feature] for feature in ordinal_features])),\n",
    "        ('nominal', OneHotEncoder(handle_unknown='ignore'), nominal_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing pipeline to Ames\n",
    "transformed_data = preprocessor.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c60097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed feature matrix shape: {X_train_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': range(1, 31, 5),\n",
    "    'n_estimators': range(20, 220, 20)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f0aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== HYPERPARAMETER TUNING WITH GRIDSEARCHCV ===\")\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    rf_model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "print(\"Training models with different hyperparameter combinations...\")\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV R² score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24268f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model\n",
    "rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "print(f\"\\nMaking predictions with best model:\")\n",
    "print(f\"Best model parameters: {rf_model.get_params()}\")\n",
    "y_train_pred = rf_model.predict(X_train_processed)\n",
    "y_test_pred = rf_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate metrics for log scale\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\n=== MODEL PERFORMANCE (Log Scale) ===\")\n",
    "print(f\"Training R²: {train_r2:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Training MAE: {train_mae:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "# Get feature names after preprocessing\n",
    "numeric_feature_names = numeric_features\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "categorical_feature_names = cat_encoder.get_feature_names_out(categorical_features).tolist()\n",
    "all_feature_names = numeric_feature_names + categorical_feature_names\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\n=== TOP 20 FEATURE IMPORTANCES ===\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with best model\n",
    "cv_scores = cross_val_score(rf_model, X_train_processed, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\n=== CROSS-VALIDATION RESULTS (BEST MODEL) ===\")\n",
    "print(f\"CV R² scores: {cv_scores}\")\n",
    "print(f\"Mean CV R²: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV R²: {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional grid search results analysis\n",
    "print(f\"\\n=== GRID SEARCH ANALYSIS ===\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(f\"Top 5 parameter combinations:\")\n",
    "top_results = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(f\"  {row['mean_test_score']:.4f} (±{row['std_test_score']:.4f}): {row['params']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d59fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted (Log Scale)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.6, color='steelblue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual LogSalePrice')\n",
    "plt.ylabel('Predicted LogSalePrice')\n",
    "plt.title(f'Actual vs Predicted (Log Scale)\\nR² = {test_r2:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals (Log Scale)\n",
    "plt.figure(figsize=(10, 8))\n",
    "residuals = y_test - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted LogSalePrice')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot (Log Scale)')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c04763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Top 15)\n",
    "plt.figure(figsize=(12, 10))\n",
    "top_15 = feature_importance.head(15)\n",
    "plt.barh(range(len(top_15)), top_15['importance'])\n",
    "plt.yticks(range(len(top_15)), [f[:25] + '...' if len(f) > 25 else f for f in top_15['feature']])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction distribution (Original Scale)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist(y_test_original, alpha=0.7, label='Actual', bins=30, color='blue')\n",
    "plt.hist(y_test_pred_original, alpha=0.7, label='Predicted', bins=30, color='orange')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution: Actual vs Predicted Prices')\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1000:.0f}K'))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ad0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
